<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Google Font (IBM Plex Sans Condensed) -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans+Condensed:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap"
        rel="stylesheet"
    >

    <!-- Bootstrap (5.2.3) -->
    <link rel="stylesheet" href="../../css/bootstrap.css">  <!-- %UPDATE% -->
    <script defer src="../../js/bootstrap.bundle.min.js"></script>  <!-- %UPDATE% -->

    <!-- Favicon. -->
    <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png">
    <link rel="manifest" href="/favicon/site.webmanifest">
    <link rel="mask-icon" href="/favicon/safari-pinned-tab.svg" color="#5bbad5">
    <link rel="shortcut icon" href="/favicon/favicon.ico">
    <meta name="msapplication-TileColor" content="#da532c">
    <meta name="msapplication-config" content="/favicon/browserconfig.xml">
    <meta name="theme-color" content="#ffffff">

    <link rel="stylesheet" href="../../css/website-base.css">  <!-- %UPDATE% -->
    <title>ML Tutorials: Data Wrangling</title>
</head>
<body>
    <!-- Header for title of webpage. -->
    <header class="container-fluid">
        <div class="row py-4 bg-primary">
            <h1 class="col text-center text-white">
                MACHINE LEARNING TUTORIALS
            </h1>
        </div>
    </header>
    <!--- Navigation banner. -->
    <nav class="navbar navbar-expand-lg sticky-top py-0 navbar-dark bg-secondary">
        <!-- Container for entire navbar. -->
        <div class="container-fluid justify-content-end px-1">
            <!-- Hamburger menu that appears when screen gets smaller. -->
            <button class="navbar-toggler my-1" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNavDropdown">
                <span class="navbar-toggler-icon"></span>
            </button>
            <!-- Container for navbar items. -->
            <div class="collapse navbar-collapse justify-content-end" id="navbarNavDropdown">
                <ul class="navbar-nav">
                    <li class="nav-item mx-4">
                        <a class="nav-link text-center" href="../../index.html">Home</a>  <!-- %UPDATE% -->
                    </li>
                    <li class="nav-item mx-4">
                        <a class="nav-link text-center" href="../../tutorials.html">Tutorials</a>  <!-- %UPDATE% -->
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Outer wrapper for main content. -->
    <div class="container-fluid" id="contentWrapper">
        <div class="row">
            <div class="col-md-1 col-lg-2 col-xxl-3"></div>
            <!-- Container for main content. -->
            <div class="col-12 col-md-10 col-lg-8 col-xxl-6 my-md-4 py-3 py-sm-4 px-0 px-sm-3 bg-white">
                <section class="container-fluid">
                    <!-- Title. -->
                    <div class="row">
                        <h2 class="col mb-3 mx-2 mx-sm-1 text-start border-start border-3 border-secondary text-primary">
                            ML Tutorials: Data Wrangling
                        </h2>
                    </div>
                    <!-- Title/image. -->
                    <div class="row">
                        <div class="d-flex justify-content-center">
                            <img
                                class="img-fluid"
                                src="../../imgs/data-wrangling.png"
                                alt="[Enter image here]"
                                width=100%
                            >  <!-- %UPDATE% -->
                        </div>
                    </div>
                    <!-- Description. -->
                    <div class="row mt-2 mb-3">
                        <div class="col">
                            <p class="pt-2">
                                Once you have identified relevant data sources and collected it into one cohesive dataset, it's easy to assume the data is ready to be fitted to a model. However, in the real world data is messy. Some values may be missing, integers could be stored as strings, or calculated fields could be miscalculated. <b><i>Data Wrangling</i></b> is the process of identifying all these errors and gets rid of them. This tutorial will cover the following learning objectives:
                            </p>
                            <ul>
                                <li>What is Data Data Wrangling?</li>
                                <li>How to Handle Missing Values</li>
                                <li>Common String Operations</li>

                            </ul>
                        </div>
                    </div>
                    <div>
                        <h2 class="mt-5 px-4 px-sm-3 border-start border-3 border-secondary">What is Data Wrangling?</h2> <br>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/iTDltBXOHVM?si=IRe90uDu0i5k_jDj" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h4 class="pt-4">Summary</h4>
                        <ul>
                            <li class="pt-1"><b><i>Data Wrangling</i></b>, also known as <b><i>Data Cleaning</i></b>, is the process of transforming raw data into interpretable data.</li>
                            <li class="pt-2">In the context of Machine Learning, Data Wrangling is a powerful process that allows you to analyze your data using a process called <b><i>Exploratory Data Analysis</i></b>.</li>
                            <li class="pt-2">There are six steps in the Data Wrangling process:
                                <ol>
                                    <li class="pt-2"><b>Discovering</b>. In this step, you analyze the schema (structure) of your dataset to understand what each feature represents, its potential impact on the label, and potential features that could be extracted from current features.</li>
                                    <li class="pt-2"><b>Structuring</b>. Most of the time, you will be working with nested structures (e.g., JSON strings, nested arrays) that will need to be expanded to obtain the actual values. In this step, you will obtain the actual structure of the data from your dataset and normalize the features across all values. This invovles ensuring all values have the same structure to keep your data consistent.</li>
                                    <li class="pt-2"><b>Cleaning</b>. In this step, you will identify steps that need to be taken to make sure your features have the correct data types, nested structures have been extracted and aligned, null/missing values have been handled appropriately (see next sub-section for details), and categorical variables are labeled appropriately.</li>
                                    <li class="pt-2"><b>Enriching</b>. Once you have a formalized pipeline to clean your data, it's wise to collect more data to provide your model with more clarity and reduce bias in its predicitons.</li>
                                    <li class="pt-2"><b>Validating</b>. In this step, you will apply your organizations Data Quality standards to ensure categories are labeled appropriately (e.g., all records representing "Walmart" all have the same spelling), numeric values are within an acceptable range (e.g., no customers over the age of 100), and all numeric features are of a numeric data type (e.g., an integer column could be shown as a string by your compiler).</li>
                                    <li class="pt-2"><b>Publishing</b>. In this step, you export your cleaned and validated data to your organization's data repository (e.g, an S3 Bucket, Data Warehouse, Data Lake) to be consumed by other models or reporting dashboards.</li>
                                </ol>
                            </li>
                            <li class="pt-2"><b>NOTE:</b> Data Wrangling typically takes 70-80% of a Machine Learning project, thus it's arguably the most boring. However, if this step is skipped, you won't have a job much longer.</li>
                        </ul>
                        <h2 class="mt-5 px-4 px-sm-3 border-start border-3 border-secondary">Handling Missing Values</h2> <br>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/FPvMBl8LvGA?si=kyeh9Yd4ElSRw-4-&amp;start=142" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h4 class="pt-4">Summary</h4>
                        <ul>
                            <li class="pt-1">Missing values are a common occurrence in source systems. These can occur due to a skipped entry on a survey, an unknown value collected from an IOT sensor, or a value that couldn't be computed due to lack of data in other fields.</li>
                            <li class="pt-2">When identifying missing values in a dataset, it can be easy to simply filter them out or fill them with a default value. However, it's HIGHLY recommended that you analyze your data model and see if you can retrieve the data from other source systems (e.g., perform a join to collect data from other tables in a data warehouse).</li>
                            <li class="pt-2">If only 1% of the values in a particular field are missing, it's generally acceptable to omit those records from the dataset. On the other hand, if 99% of the values in a particular field are missing, it's generally acceptable to omit the field from the dataset.</li>
                            <li class="pt-2">It's generally acceptable to omit missing data from a dataset when the values in the other fields are random in nature and are correlated in any sense. However, if the records with missing values have other field values in common, it's worth investigating further using EDA.</li>
                            <li class="pt-2">One of the most common ways ML Engineers fill missing values is by using a process called Imputation. <b><i>Imputation</i></b> is the process of inferring the value of a missing data point by analyzing the points around it. This is done using several methods including:
                            <ul>
                                <li class="pt-2"><b>Mean/Median Imputation:</b> This is used to fill in missing values for numerical fields. In this method, you find the Mean or Median of the existing values in the field and use that value to fill in the missing values. This keeps the value normally distributed.</li>
                                <li class="pt-2"><b>Categorical Imputation:</b> This is used to fill in missing values for non-numeric fields. In this method, you find the most common value in the field and use that to fill in the missing values. This should only be used when one category occurs more frequently in the field.</li>
                                <li class="pt-2"><b>Interpolation:</b> This is used to fill in missing values for numeric fields on a time-series axis. In this method, you plot the existing data on a line chart and then connect the gaps by getting the average of the points on either end of the gap.</li>
                                <li class="pt-2"><b>Supervised Imputation:</b> This is used to fill in the missing values of any specified field using a supervised model. In this method, you train a model using your current dataset and set the field you want to impute as your label. The model will then use it's knowledge to predict the values based on the features provided.</li>
                            </ul></li>
                            <li class="pt-2"><b>NOTE:</b> Be careful when omitting records from a dataset. Although they may contain missing values, they could provide valuable insight to the model with the values stored in the other fields.</li>
                            <li class="pt-2"><b>NOTE:</b> A general rule of thumb is to omit features when 70% or more of the values are missing.</li>
                            <li class="pt-2"><b>NOTE:</b> The Supervised Imputation method should be used sparingly, as it adds compelxity to your project and forces you to change your model for only a small portion of your data.</li>
                        </ul>
                        <h2 class="mt-5 px-4 px-sm-3 border-start border-3 border-secondary">Collecting Data from APIs</h2> <br>
                        <h6><b>What is an API?</b></h6>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/ByGJQzlzxQg?si=ijOaSTAPELp2fUrf" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h6><b>What are HTTP Request Methods?</b></h6>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/PO3kQeNMbaY?si=231wt2TfE5pEWnzJ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h4 class="pt-4">Summary</h4>
                        <ul>
                            <li class="pt-1"> An <b><i>Application Programming Interface (API)</i></b> is simply a tool used to connect applications. An <b><i>Application</i></b> can be thought of as a collection fo code run on a server.</li>
                            <li class="pt-2">When sending data between applications, the data collected must be the same "shape", or have the same definition as stated in the backend. This shape of data is known as a <b><i>schema</i></b> and is used to explicitly define the required fields for each input record.</li>
                            <li class="pt-2">When using an external API (an API developed by an organization other than your own), you'll liekly need an <b><i>API Key</i></b>. This acts as a login token to grant you access to the API's backend. These are used to prevent hackers from performing Brute Force attacks on the API's servers.</li>
                            <li class="pt-2"><b><i>API Documentation</i></b> is used to keep track of all the different types of records stored in the API backend, what they are used for, what permissions are required, and how to obtain an API Key. Before using any API, it's critical to read through the documentation to get a better understanding of how to get the correct information.</li>
                            <li class="pt-2">When a client communicates with a server, it needs to specify which action the server needs to take. This is done via <b><i>HTTP Requests</i></b>. There are several HTTP Request Methods:
                            <ul>
                                <li><b>GET:</b> This is used to retrieve data from a source. This is the most common method used by ML Engineers during the Data Collection stage of the ML Lifecycle.</li>
                                <li><b>PUT:</b> This is used to update data within a source. This is used by Software Engineers to continuously update URL paths on a website or data objects on a backend server.</li>
                                <li><b>POST:</b> This is used to insert new data to a source. This is used by ML Engineers to input users entries into the training dataset. This is used at the end of the ML Lifecycle when you have deployed your model into Production.</li>
                                <li><b>DELETE:</b> This is used to remove data from a source. This is used by Software Engineers to continuously keep the data presented on websites or backend servers relevant and comply with data security standards.</li>
                            </ul></li>
                            <li class="pt-2"><b><i>JavaScript Object Notation (JSON)</i></b> is the object format used by APIs to transport data between applications. This data is represented in a key-value pair format, similar to a dictionary in Python.</li>
                        </ul>
                        <h2 class="mt-5 px-4 px-sm-3 border-start border-3 border-secondary">Collecting Data from IOT Devices</h2> <br>
                        <h6><b>What is the Internet of Things (IOT)?</b></h6>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/6mBO2vqLv38?si=glX2NQX9__fIfNdS" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h6><b>What is Data Streaming?</b></h6>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/SLHCfIUTYZI?si=-_vXS8IS3A9wlm2V" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h4 class="pt-4">Summary</h4>
                        <ul>
                            <li class="pt-1"> The <b><i>Internet of Things (IOT)</i></b> is the connection and collaboration of internet-based devices to create "Smart" appliances. An <b><i>IOT device</i></b> is simply any piece of technology that can access the internet, such as televisions, bluetooth speakers, smart thermometers, and security cameras.</li>
                            <li class="pt-2">IOT devices can be separated into two categories:
                                <ul>
                                    <li><b>General Devices:</b> These are generic pieces of technology that are typically connected via Wi-Fi or bluetooth. Examples: Television, Smart Speaker, Smart Lightbulbs.</li>
                                    <li><b>Sensing Devices:</b> These are hardwired devices that are used to collect data in real-time for use in either predicitive analytics or descriptive analytics. These use data streams to send data in real-time to mobile applications for user consumption.</li>
                                </ul>
                            </li>
                            <li class="pt-2"><b><i>Data Streaming</i></b> is the continuous flow of data as it's generated from a source so that it can be used for real-time processing and analytics.</li>
                            <li class="pt-2"><b><i>Batch Scheduling</i></b> refers to the collection and processing of data in batches at a regularly scheduled interval. A good example of this is retail transactions. Rather than getting data on how much money a retail store made every hour, it can be collected and aggregated on a daily basis.</li>
                            <li class="pt-2">In the context of machine learning, Data Streaming is useful for creating real-time predicitons. For example, suppose you are tasked with creating a model that predicts, in real-time whether a financial transaction is fraudulent or not. Rather than querying a data warehouse every minute or hour to analyze these records, it would be helpful to get the results as close to real-time as possible.</li>
                            <li class="pt-2">Data Streams capture events. In the context of Data Streaming, <b><i>Events</i></b> can be defined as an action that occurs at a specific point in time. This could be when a user clicks a button on a website, a sensor is triggered based on an algorithm, or a sale takes place online.</li>
                            <li class="pt-2"><b><i>Producers</i></b> are the data sources for data streams. This is where IOT comes into play. IOT devices can generate large amounts of data depending on their use cases. These producers are setup to write data to a log file, to maintain data integrity, then each record is placed in a queue, similar to a line in a supermarket.</li>
                            <li class="pt-2"><b><i>Consumers</i></b> are the end point that the consumers are sending data to. This could be a staging area, such as a cloud storage bucket or data lake, or a NoSQL database designed to handle incoming data streams, such as Apache Druid.</li>
                            <li class="pt-2"><b>NOTE:</b> To help keep Data Streams efficient, message queues are typically parallel processed by aggregating similar events into separate queues. This helps keep things organized and running smoothly.</li>
                        </ul>
                        <h2 class="mt-5 px-4 px-sm-3 border-start border-3 border-secondary">Collecting Data from Data Lakes</h2> <br>
                        <iframe width="650" height="400" src="https://www.youtube.com/embed/pQuHDlF8N04?si=RkB33CN_aznqNKOc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe> <br><br>
                        <h4 class="pt-4">Summary</h4>
                        <ul>
                            <li class="pt-1"> A <b><i>Data Lake</i></b> is a centralized repository for all raw, unstructured data within an organization. These are commonly used to store images, binary files, log files, and other types of data that can't be stored in a traditional relational database architecture.</li>
                            <li class="pt-2">Nowadays, the most common form of Data Lakes are Cloud Storage Buckets. These allow you to store very large amounts of data (think petabyte-scale) in a single location, or multiple locations to sort items into groups, without having to fit a strict schema.
                            </li>
                            <li class="pt-2">Rather than using SQL or a similar query language to retrieve files from a data lake, cloud providers provide APIs and Python libraries to allow easy access to objects stored within a specific bucket.</li>
                        </ul><br>
                        <!-- Previous/Next Topic buttons. -->
                    <div class="row mt-4 mt-md-5 mb-2 px-3">
                        <div class="col-0 col-sm-8">
                            <a
                            class="col-12 col-sm-4 btn btn-outline-primary py-2 fs-5"
                            href="../Machine Learning/Data-Collection.html">
                            Previous Topic
                            </a>
                        </div>
                        <!-- <a
                            class="col-12 col-sm-4 btn btn-outline-primary py-2 fs-5"
                            href="../Machine Learning/ML-Lifecycle.html">
                            Next Topic
                        </a> -->
                    </div>
                </section>
            </div>
            <div class="col-md-1 col-lg-2 col-xxl-3"></div>
        </div>
    </div>
    <!-- Footer at bottom of page. -->
    <footer class="container-fluid bg-secondary">
        <div class="row align-items-center h-100">
            <h4 class="col m-0 text-center text-white">
                © 2023 Data Science Club @ UVU
            </h4>
        </div>
    </footer>
</body>
</html>
